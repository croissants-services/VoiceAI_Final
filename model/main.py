import asyncio
import os
from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from pydantic import BaseModel
from typing import Literal, Union
from enum import Enum
import sys

root = os.path.join(os.path.dirname(os.getcwd()))
sys.path.append(root)

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from .stt import STTModel
from .llm import LLMModel
from .tts import TTSModel

# --- add to your FastAPI websocket handler file (e.g., main.py) ---
import base64, struct, numpy as np
import json
from datetime import datetime

def _audio_stats_from_pcm16le(pcm_bytes: bytes):
    if not pcm_bytes:
        return {"n": 0, "rms": 0.0, "peak": 0}
    if len(pcm_bytes) % 2 != 0:
        return {"n": 0, "rms": 0.0, "peak": 0, "error": "bytes not even (not int16-aligned)"}
    n = len(pcm_bytes) // 2
    samples = struct.unpack("<" + "h"*n, pcm_bytes[:n*2])
    arr = np.frombuffer(np.asarray(samples, dtype=np.int16), dtype=np.int16).astype(np.float32)
    rms = float(np.sqrt(np.mean(arr**2)))
    peak = int(np.max(np.abs(arr)))
    return {"n": n, "rms": rms, "peak": peak}

def _maybe_decode_payload(payload: bytes | str):
    """
    Decodes incoming payload into raw PCM bytes when possible.
    Priority:
      1) bytes/bytearray â†’ assume raw PCM ("binary")
      2) JSON string with base64 under common keys ("json(base64)")
      3) bare base64 string ("base64")
      4) fallback to UTF-8 bytes of the text ("text")
    """
    # 1) Direct binary
    if isinstance(payload, (bytes, bytearray)):
        return bytes(payload), "binary"

    # 2) JSON string with base64 field
    if isinstance(payload, str):
        # Try to parse JSON and extract a base64 field if present
        try:
            obj = json.loads(payload)
            if isinstance(obj, dict):
                # typical keys seen in VoiceAI: chunk_data, data, audio_data
                cand_keys = [
                    "chunk_data", "data", "audio_data", "audio", "b64", "base64"
                ]
                for k in cand_keys:
                    v = obj.get(k)
                    if isinstance(v, str):
                        try:
                            decoded = base64.b64decode(v, validate=True)
                            return decoded, "json(base64)"
                        except Exception:
                            # keep searching other keys
                            pass
        except Exception:
            # not JSON or not a dict â†’ fall through to direct base64
            pass

        # 3) Bare base64 string
        try:
            decoded = base64.b64decode(payload, validate=True)
            return decoded, "base64"
        except Exception:
            # 4) Fallback to raw UTF-8 bytes (for logging/diagnostics)
            return payload.encode("utf-8", errors="ignore"), "text"

    # Unknown type
    return b"", "unknown"

async def _log_audio_chunk(prefix: str, raw: bytes | str):
    data, dtype = _maybe_decode_payload(raw)
    # raw PCMìœ¼ë¡œ ê°€ì •í•˜ê³  í†µê³„ ì°ê¸°
    stats = _audio_stats_from_pcm16le(data)
    now = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"[WS][{now}] {prefix} type={dtype} bytes={len(data)} stats={stats}")
    # í¬ë§· íŒíŠ¸
    if dtype == "text":
        print("[WARN] text frame ìˆ˜ì‹  â€” base64 or JSON ë˜í•‘ ì—¬ë¶€ í™•ì¸ í•„ìš”")
    if len(data) and len(data) % 2 != 0:
        print("[WARN] int16 ì •ë ¬ ì˜¤ë¥˜(ë°”ì´íŠ¸ ìˆ˜ê°€ 2ì˜ ë°°ìˆ˜ ì•„ë‹˜) â€” ì¸ì½”ë”© ë˜ëŠ” ì „ì†¡ ê²½ë¡œ ì ê²€ í•„ìš”")

# --- STT ì§„ë‹¨ ë¡œê·¸ í—¬í¼ë“¤ ---
def _log_stt_config(stt_obj):
    enc = getattr(stt_obj, "encoding", None) or getattr(stt_obj, "ENCODING", None) or "(unknown)"
    sr = getattr(stt_obj, "sample_rate", None) or getattr(stt_obj, "SAMPLE_RATE", None) or "(unknown)"
    ch = getattr(stt_obj, "channels", None) or getattr(stt_obj, "CHANNELS", None) or "(unknown)"
    lang = getattr(stt_obj, "language", None) or getattr(stt_obj, "LANGUAGE", None) or "(unknown)"
    print(f"[STT] config: encoding={enc} sample_rate={sr} channels={ch} language={lang}")

async def _maybe_set_stt_logging_hooks(stt_obj):
    """STTModelì´ í›… ë“±ë¡ì„ ì§€ì›í•˜ëŠ” ê²½ìš°(ì„ íƒì ), ì „ì†¡ ë°”ì´íŠ¸/ê²°ê³¼ ë¡œê·¸ë¥¼ ì°ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        setter = getattr(stt_obj, "set_logging_hooks", None)
        if callable(setter):
            def on_send_frame(frame_bytes: bytes):
                print(f"[STT] send frame bytes={len(frame_bytes)}")
            def on_result(is_final: bool, duration_s: float, text: str | None, confidence: float | None = None):
                # durationê³¼ confidenceê°€ ì—†ìœ¼ë©´ '(n/a)'ë¡œ ì¶œë ¥
                d = f"{duration_s:.2f}s" if isinstance(duration_s, (int, float)) else "n/a"
                c = f"{confidence:.2f}" if isinstance(confidence, (int, float)) else "n/a"
                t = (text or "").strip()
                print(f"[STT] got result: is_final={is_final} dur={d} text=\"{t}\" conf={c}")
            setter(on_send_frame=on_send_frame, on_result=on_result)
    except Exception as e:
        print(f"[STT] hook setup skipped: {e}")

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(dotenv_path=".env")

# --- 0. pydantic ëª¨ë¸ ì •ì˜ ---
class ChatRole(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"

class ChatMessage(BaseModel):
    id: str
    role: ChatRole
    text: str

class SttInterimResultMessage(BaseModel):
    type: Literal['stt_interim_result']
    transcript: str

class VoiceInput(BaseModel):
    type: Literal['voice']
    data: str  # ë˜ëŠ” bytes, í•„ìš”ì— ë”°ë¼
    
class VoiceChunk(BaseModel):
    type: Literal['voicechunk']
    chunk_data: str  # ë˜ëŠ” bytes
    sequence: int = 0
    is_final: bool = False

class TTSAudioChunk(BaseModel):
    type: Literal['tts_audio']
    audio_data: bytes
    sequence: int = 0
    is_final: bool = False

class ErrorMessage(BaseModel):
    type: Literal['error']
    message: str
    error_code: str = "UNKNOWN_ERROR"

# ë©”ì‹œì§€ íƒ€ì… ìœ ë‹ˆì˜¨
MessageType = Union[
    ChatMessage, 
    SttInterimResultMessage, 
    VoiceInput, 
    VoiceChunk,
    TTSAudioChunk,
    ErrorMessage
]

# --- 1. ëª¨ë“  AI ëª¨ë¸ì„ ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ---
class SpeechService:
    def __init__(self):
        print("SpeechService ì´ˆê¸°í™” ì‹œì‘...")
        self.stt_model = STTModel()
        self.llm_model = LLMModel()
        self.tts_model = TTSModel()
        print("SpeechService ì´ˆê¸°í™” ì™„ë£Œ.")

# --- 2. FastAPI ì•± ë° ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„± ---
app = FastAPI()

@app.on_event("startup")
async def _on_startup():
    print("[FastAPI] startup complete â€” app is ready")

speech_service = SpeechService()

@app.get("/healthz")
async def healthz():
    return {"ok": True}

@app.get("/diag")
async def diag():
    stt = speech_service.stt_model
    enc = getattr(stt, "encoding", None) or "(unknown)"
    sr = getattr(stt, "sample_rate", None) or "(unknown)"
    ch = getattr(stt, "channels", None) or "(unknown)"
    lang = getattr(stt, "language", None) or "(unknown)"
    return {
        "ok": True,
        "stt": {"encoding": enc, "sample_rate": sr, "channels": ch, "language": lang}
    }

# --- 3. WebSocket ì—°ê²° ìƒíƒœ í™•ì¸ í—¬í¼ í•¨ìˆ˜ ---
def is_websocket_connected(websocket: WebSocket) -> bool:
    try:
        # WebSocket ìƒíƒœ í™•ì¸ ë°©ë²•ë“¤
        if hasattr(websocket, 'client_state'):
            from fastapi.websockets import WebSocketState
            return websocket.client_state == WebSocketState.CONNECTED
        elif hasattr(websocket, '_state'):
            return websocket._state == 1  # CONNECTED state
        else:
            # fallback: client ê°ì²´ì˜ closed ì†ì„± í™•ì¸
            return hasattr(websocket.client, 'closed') and not websocket.client.closed
    except Exception:
        return False

# --- 4. WebSocket ì—”ë“œí¬ì¸íŠ¸ ì •ì˜ ---
@app.websocket("/ws/s2s")
async def websocket_endpoint(websocket: WebSocket):
    client_host = websocket.client.host
    client_port = websocket.client.port
    print(f"[Model] WebSocket connection attempt from {client_host}:{client_port}")
    await websocket.accept()
    print(f"[Model] WebSocket connection accepted for {client_host}:{client_port}")
    
    # ì—°ê²° ìƒíƒœ ì¶”ì 
    is_connected = True
    
    try:
        # --- ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ ìœ„í•œ while ë£¨í”„ ---
        while is_connected:

            try:
                # --- STT ë‹¨ê³„ ---
                print(f"[Model] Handing WebSocket directly to STT (no pre-read) for {client_host}:{client_port}...")
                _log_stt_config(speech_service.stt_model)
                await _maybe_set_stt_logging_hooks(speech_service.stt_model)
                full_transcript = await speech_service.stt_model.transcribe_stream(websocket)
                print(f'[Model] Received full transcript: {full_transcript}')
                if not full_transcript:
                    print("[STT] empty final transcript â€” waiting for next turn")
                    await asyncio.sleep(0.05)
                    continue
                print(f"[STT] summary: final_text=\"{(full_transcript or '').strip()}\"")
                # ì—°ê²° ìƒíƒœ í™•ì¸
                if not is_websocket_connected(websocket):
                    print("ğŸ”Œ WebSocket ì—°ê²° ìƒíƒœ ë³€ê²½ ê°ì§€")
                    break
                
                if full_transcript:
                    print(f"ğŸ¤ ìµœì¢… STT ê²°ê³¼: {full_transcript}")

                    # --- LLM + TTS íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ---
                    text_generator = speech_service.llm_model.generate_text_stream(full_transcript)
                    audio_chunk_generator = speech_service.tts_model.synthesize_audio_stream(text_generator)

                    # ìƒì„±ë˜ëŠ” ìŒì„± ì¡°ê°ì„ ì¦‰ì‹œ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
                    async for audio_chunk in audio_chunk_generator:
                        # ì „ì†¡ ì „ ì—°ê²° ìƒíƒœ ì¬í™•ì¸
                        if not is_websocket_connected(websocket):
                            print("ğŸ”Œ ì „ì†¡ ì¤‘ ì—°ê²° ëŠì–´ì§ ê°ì§€")
                            is_connected = False
                            break
                        await websocket.send_bytes(audio_chunk)
                    
                    print("ğŸ”Š ìŒì„± ì‘ë‹µ ì „ì†¡ ì™„ë£Œ")
                
                # ì§§ì€ ëŒ€ê¸°ë¡œ CPU ì‚¬ìš©ë¥  ìµœì í™”
                await asyncio.sleep(0.1)
                
            except WebSocketDisconnect:
                print("ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ (ë‚´ë¶€)")
                is_connected = False
                break
            except asyncio.CancelledError:
                print("ğŸ”Œ ì‘ì—… ì·¨ì†Œë¨")
                is_connected = False
                break
            except Exception as e:
                print(f"ğŸš« ë‚´ë¶€ ë£¨í”„ ì˜¤ë¥˜: {e}")
                # ì¼ë¶€ ì˜¤ë¥˜ëŠ” ê³„ì† ì§„í–‰ ê°€ëŠ¥
                if "disconnect" in str(e).lower() or "close" in str(e).lower():
                    is_connected = False
                    break
                # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
                continue

    except WebSocketDisconnect:
        print(f"[Model] WebSocket disconnected (external) for {client_host}:{client_port}")
    except Exception as e:
        print(f"[Model] An overall exception occurred for {client_host}:{client_port}: {e}")
    finally:
        # ì •ë¦¬ ì‘ì—…
        try:
            # STT ëª¨ë¸ì˜ ì—°ê²° ì •ë¦¬ (Deepgram ë“±)
            if hasattr(speech_service.stt_model, 'cleanup'):
                await speech_service.stt_model.cleanup()
        except Exception as cleanup_error:
            print(f"[Model] Error during cleanup for {client_host}:{client_port}: {cleanup_error}")
        

        print(f"[Model] Client session ended for {client_host}:{client_port}")
